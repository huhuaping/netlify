<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>SEM-slide-eng-part1-why.knit</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/duke-blue.css" rel="stylesheet" />
    <link href="libs/remark-css/hygge-duke.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/htmlwidgets/htmlwidgets.js"></script>
    <link href="libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
    <script src="libs/datatables-binding/datatables.js"></script>
    <script src="libs/jquery/jquery-3.6.0.min.js"></script>
    <link href="libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
    <link href="libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
    <script src="libs/dt-core/js/jquery.dataTables.min.js"></script>
    <link href="libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
    <script src="libs/crosstalk/js/crosstalk.min.js"></script>
    <link rel="stylesheet" href="../mycss/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="../mycss/my-font-eng.css" type="text/css" />
    <link rel="stylesheet" href="../mycss/my-custom-for-video-roomy.css" type="text/css" />
    <link rel="stylesheet" href="../mycss/text-box.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

background-image: url("../pic/slide-front-page.jpg")
class: center,middle
count: false

# Advanced Econometrics III

## (高级计量经济学III 全英文)

&lt;!---    chakra: libs/remark-latest.min.js ---&gt;

### Hu Huaping (胡华平 )

### NWAFU (西北农林科技大学)


### School of Economics and Management (经济管理学院)

### huhuaping01 at hotmail.com

### 2023-04-07







<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 70px;
z-index: 0;
background-image: url(../pic/logo/nwafu-logo-circle-wb.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:0.2em;left:1em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.title-slide):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>


---
count: false
class: center, middle, duke-orange,hide_logo

# Part 2：Simultaneous-Equation Models (SEM)

.large[

Chapter 17. Endogeneity and Instrumental Variables

.red[Chapter 18. Why Should We Concern SEM ?]

Chapter 19. What is the Identification Problem?

Chapter 20. How to Estimate SEM ?

]


???

In the following three chapters, we will focus on simultaneous equation models.

---
class: center, middle,inverse
name: chpt18

## Chapter 18. Why Should We Concern SEM ?

[18.1 The Nature of Simultaneous-Equation Models](#nature)

[18.2 Notes and Relative Definitions](#notation)

[18.3 Is OLS Method Still applicable?](#OLS-apply)

???

Firstly, let us answer the question that why should we concern SEM ?

---
layout: false
class: center, middle, duke-softblue,hide_logo
name: nature

## 18.1 The Nature of Simultaneous-Equation Models

???

So, the most important issue we should know about is the nature of the SEM.

---
layout: true
  
&lt;div class="my-header-h2"&gt;&lt;/div&gt;
&lt;div class="watermark1"&gt;&lt;/div&gt;
&lt;div class="watermark2"&gt;&lt;/div&gt;
&lt;div class="watermark3"&gt;&lt;/div&gt;

&lt;div class="my-footer"&gt;&lt;span&gt;huhuaping@  &lt;a href="#chpt18"&gt; Chapter 18. Why Should We Concern SEM ? &lt;/a&gt; | &amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&lt;a href="#nature"&gt;18.1 The Nature of Simultaneous-Equation Models &lt;/a&gt;&lt;/span&gt;&lt;/div&gt; 



---

### Definition and basic format of SEM

- **Simultaneous Equations Models (SEM)**: A system of equations consisting of several equations with interrelated or jointly influence.



- The basic and simple SEM is

`$$\begin{cases}
  \begin{align}
    Y_{1 i}=\beta_{10}+\gamma_{12} Y_{2 i}+\beta_{11} X_{1 i}+u_{i1} \\
    Y_{2 i}=\beta_{20}+\gamma_{21} Y_{1 i}+\beta_{21} X_{1 i}+u_{i2}
  \end{align}
\end{cases}$$`


???

Next, I will show you four SEM examples from classical economic textbooks, and another two real life SEM examples.


---

### Example 1: Demand-and-Supply System

**Demand-and-Supply System**:

`$$\begin{cases}
  \begin{align}
  \text { Demand function: } &amp; {Q_{t}^{d}=\alpha_{0}+\alpha_{1} P_{t}+u_{1t}, \quad \alpha_{1}&lt;0} \\
  {\text { Supply function: }} &amp; {Q_{t}^{s}=\beta_{0}+\beta_{1} P_{t}+u_{2t}, \quad \beta_{1}&gt;0} \\
  {\text {Equilibrium condition: }} &amp; {Q_{t}^{d}=Q_{t}^{s}}
  \end{align}
\end{cases}$$`

???

This slide shows the classic demand and supply SEM. 

The first eq is the demand function, and the second one is the supply function, the last one is the market equilibrium identity.

---

### Example 2: Keynesian Model of Income Determination

**Keynesian Model of Income Determination**:

`$$\begin{cases}
  \begin{align}
    C_t &amp;= \beta_0+\beta_1Y_t+\varepsilon_t &amp;&amp;\text{(consumption function)}\\
    Y_t &amp;= C_t+I_t &amp;&amp;\text{(income identity)}
  \end{align}
\end{cases}$$`

???

/'keinziən/

This slide shows the Keynesian Model of Income Determination, which consists of two equations.

And I will show you more details later in this chapter.

---

### Example 3: The IS Model

Macroeconomics goods market equilibrium model, also known as **IS Model**:

`$$\begin{cases}
  \begin{align}
  \text { Consumption function: } &amp; C_{t}=\beta_{0}+\beta_{1} Y_{d t} +u_{1t} &amp; &lt;\beta_{1}&lt;1 \\ 
  \text { Tax function: } &amp; T_{t}=\alpha_{0}+\alpha_{1} Y_{t} +u_{2t}&amp; \quad 0&lt;\alpha_{1}&lt;1  \\ 
  \text { Investment function: } &amp; I_{t}=\gamma_{0}+\gamma_{1} r_{t} +u_{3t} \\ 
  \text { Definition: } &amp; \gamma_{d t}=Y_{t}-T_{t} \\
  \text { Government expenditure: } &amp; G_{t}=\bar{G} \\ 
  \text { National income identity: } &amp; Y_{t}=C_{t}+I_{t}+G_{t}
  \end{align}
\end{cases}$$`


&gt;where:
&gt;
`\(Y=\)`national income;
`\(Y_d=\)`disposable income;
`\(r=\)`interest rate;
`\(\bar{G}=\)`given level of government expenditure

???

Here, the IS system contains totally six equations.


---

###  Example 4: The LM Model

Macroeconomics money market equilibrium system, also known as **LM Model**:

`$$\begin{cases}
  \begin{align}
  {\text { Money demand function: }} &amp; {M_{t}^{d}=a+b Y_{t}-c r_{t}} +u_{t} \\ 
  {\text { Money supply function: }} &amp; {M_{t}^{s}=\bar{M}} \\
  {\text { Equilibrium condition: }} &amp; {M_{t}^{d}=M_{t}^{s}}
  \end{align}
\end{cases}$$`

&gt;Where: 
&gt;
`\(Y=\)`income;
`\(r=\)`interest rate;
`\(\bar{M}=\)`assumed level of money supply.

???
Thus, the LM system contains totally 3 equations.

---

###  Example 5: Klein's model I

**Klein's model I**：

`$$\begin{cases}
  \begin{align}
  \text { Consumption function: }  &amp; C_{t}=\beta_{0}+\beta_{1} P_{t}+\beta_{2}\left(W+W^{\prime}\right)_{t}+\beta_{3} P_{t-1}+u_{ t1} \\ 
  \text { Investment function: } &amp; I_{t} =\beta_{4}+\beta_{5} P_{t}+\beta_{6} P_{t-1}+\beta_{7} K_{t-1}+u_{ t2} \\ 
  \text { Demand for labor: } 
   &amp; w_{t}= \beta_{8}+\beta_{9}\left(Y+T-W^{\prime}\right)_{t}  +\beta_{10}\left(Y+T-W^{\prime}\right)_{t-1}+\beta_{11} t+u_{ t3} \\ \text { Identity: } &amp; Y_{t} = C_{t}+I_{t}+C_{t} \\ 
  \text { Identity: }  &amp; Y_{t}=W_{t}^{\prime}+W_{t}+P_{t} \\ 
  \text { Identity: }  &amp; K_{t}=K_{t-1}+I_{t} 
  \end{align}
\end{cases}$$`

&gt;Where: 
&gt;
`\(C=\)`consumption expenditure;
`\(Y=\)`income after tax;
`\(P=\)`proﬁts;
`\(W=\)`private wage bill;
`\(W^{\prime}=\)`government wage bill;
`\(K=\)`capital stock;
`\(T=\)`taxes.

???

This slide shows the macroeconomic Klein's model I. And it contains three stochastic equations and three identities. 

---

### Example 6: Murder Rates and Size of the police Force

Cities often want to determine how much additional **law enforcement** will decrease their **murder rates**.

`$$\begin{cases}
  \begin{align}
  \operatorname{murdpc} &amp;=\alpha_{1} \operatorname{polpc}+\beta_{10}+\beta_{11} \text {incpc}+u_{1} \\
  \text { polpc } &amp;=\alpha_{2} \operatorname{murdpc}+\beta_{20}+\text { other factors. }
  \end{align}
\end{cases}$$`


&gt; Where :
&gt;
`\(murdpc =\)`murders per capita;
`\(polpc =\)`number of police officers per capita;
`\(incpc =\)`income per capita.

???

Here, we will see an microeconomic real life example.

we assumed that merder rates is determinded by numbers of police officers and income per capita.

Meanwhile, the number of police officers will also be affected by murder rates and other factors within city districts.

---

### Example 7: Housing Expenditures and Saving

For a random household in the population, we assume that annual **housing expenditures** and **saving** are jointly determined by:

`$$\begin{cases}
  \begin{align}
  \text {housing } &amp; =\alpha_{1} \text {saving}+\beta_{10}+\beta_{11} \text {inc}+\beta_{12} e d u c+\beta_{13} \text {age}+u_{1} \\ 
  \text {saving} &amp;=\alpha_{2} \text {housing }+\beta_{20}+\beta_{21} \text {inc}+\beta_{22} e d u c+\beta_{23} \text {age}+u_{2}
  \end{align}
\end{cases}$$`

&gt; Where:
&gt;
`\(inc =\)`annual income; 
`\(saving =\)`household saving;
`\(educ =\)`education measured in years;
`\(age =\)`age measured in years.


???

Another real life example is the housing expenditures and saving system.

as you know, housing expenditures and savings are jointly determinded by income, education, age, and the disturbances. 

Meanwhile, there will be reverse causality effect between housing expenditures and houshold saving.

---

### The Nature of SEM

The essence of simultaneous equation model is **endogenous variable** problem:


- Each of these equations has its economic **causality effect**.

- Some of these equations contain **endogenous variables**.

- Sample data is only the end result of various variables, which lies  complex causal interaction behind them.

- Estimation all of the **parameters** directly by OLS method may induce problems.

???

So, What are the characteristics of the simultaneous equation model?



---

### Trufﬂes example: the story

**Trufﬂes** are delicious food materials. They are edible fungi that grow below the ground. Consider a supply and demand model for trufﬂes:

`$$\begin{cases}
  \begin{align}
    \text { Demand: } &amp; Q_{di}=\alpha_{1}+\alpha_{2} P_{i}+\alpha_{3} P S_{i}+\alpha_{4} D I_{i}+e_{d i} \\ 
    \text { Supply: } &amp; Q_{si}=\beta_{1}+\beta_{2} P_{i}+\beta_{3} P F_{i}+e_{s i}\\
    \text { Equity: } &amp; Q_{di}= Q_{si}
  \end{align}
\end{cases}$$`

&gt; where:
- 
`\(Q_i=\)`the quantity of trufﬂes traded in a particular marketplace;
- 
`\(P_i=\)`the market price of trufﬂes;
- 
`\(PS_i=\)`the market price of a substitute for real trufﬂes;
- 
`\(DI_i=\)`per capita monthly disposable income of local residents;
- 
`\(PF_i=\)`the price of a factor of production, which in this case 
is the hourly rental price of trufﬂe-pigs used in the search process.

???

So, let us sum up this section with the truffles example.

We will just walk through the sigle equation thought with the data set. 

And you should think about the difference between sigle equation model and SEM.


---

### Trufﬂes example: model variables

<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-cfc53dd0b2a5017f19f0" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-cfc53dd0b2a5017f19f0">{"x":{"filter":"none","vertical":false,"caption":"<caption>All variables<\/caption>","data":[["1","2","3","4","5"],["P","Q","PS","DI","PF"],["market price of truffles","market quantity of truffles","market price of substitute","disposable income","rental price of truffles-pigs"],["dollar/ounce","ounce","dollar/ounce","dollar/capita, monthly","dollar/hour"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>vars<\/th>\n      <th>label<\/th>\n      <th>measure<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","columnDefs":[{"className":"dt-center","targets":"_all"},{"visible":false,"targets":0},{"orderable":false,"targets":0}],"pageLength":6,"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[6,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>


???
松露案例：变量说明

案例来源：Hill, R. C., W. E. Griffiths and G. C. Lim. Principles of Econometrics 4th Edition  [M], Wiley, 2011. chpt 11。实例参考：[PoE with R](https://bookdown.org/ccolonescu/RPoE4/simultaneous-equations-models.html)

---

###  Trufﬂes example: the data set

<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-edaee1593948041aacf5" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-edaee1593948041aacf5">{"x":{"filter":"none","vertical":false,"caption":"<caption>Truffles data set (n = 30)<\/caption>","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],[29.64,40.23,34.71,41.43,53.37,38.52,54.33,40.56,67.35,49.65,58.17,66.87,49.95,64.95,52.68,61.2,80.55,89.94,70.77,57.33,46.23,77.43,83.01,70.71,66.75,76.8,83.7,81,88.44,105.45],[19.89,13.04,19.61,17.13,22.55,6.37,15.02,10.22,23.64,16.12,24.55,18.92,11.94,18.93,12.6,20.49,22.94,21.08,16.68,17.61,16.62,20.99,24.53,19.67,23.29,16.64,20.81,14.95,26.27,20.65],[19.97,18.04,22.36,20.87,19.79,15.98,17.94,17.09,22.72,15.74,24.64,23.7,15.93,23.34,15.21,26.04,22.95,27.1,23.65,20.06,26.38,24.28,26.64,22.65,19.68,23.82,28.98,18.52,28.16,28.43],[2.103,2.043,1.87,1.525,2.709,2.489,2.294,2.196,3.885,3.169,2.623,3.007,3.367,3.29,3.746,3.518,4.381,4.121,3.82,4.398,3.764,4.524,4.815,3.67,4.392,4.603,4.632,4.894,5.125,4.836],[10.52,19.67,13.74,17.95,13.71,24.95,24.17,23.61,19.52,20.03,15.38,22.98,25.76,25.17,25.82,19.31,26.02,29.65,27.45,18,18.87,24.58,25.25,24.24,22.63,27.35,27.8,30.34,24.12,34.01]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>id<\/th>\n      <th>P<\/th>\n      <th>Q<\/th>\n      <th>PS<\/th>\n      <th>DI<\/th>\n      <th>PF<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"tip","columnDefs":[{"className":"dt-center","targets":"_all"},{"visible":false,"targets":0},{"orderable":false,"targets":0}],"pageLength":8,"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100]}},"evals":[],"jsHooks":[]}</script>

---

### Trufﬂes example: the Scatter plot (P VS Q) 

&lt;img src="SEM-slide-eng-part1-why_files/figure-html/scatter-truffles-1.png" style="display: block; margin: auto;" /&gt;

---

### Trufﬂes example: the Scatter matrix

&lt;img src="SEM-slide-eng-part1-why_files/figure-html/unnamed-chunk-1-1.png" style="display: block; margin: auto;" /&gt;

---

### Trufﬂes example: the simple linear regression

Let's start with the simplest linear regression model.

Generally, we use price (P) and output (Q) data to directly conduct simple linear regression modeling:

`$$\begin{cases}
  \begin{align}
  P &amp; = \hat{\beta}_1+\hat{\beta}_2Q +e_1 &amp;&amp; \text{(simple P model)}\\
  Q &amp; = \hat{\beta}_1+\hat{\beta}_2P +e_2  &amp;&amp; \text{(simple Q model)}
  \end{align}
\end{cases}$$`





???
从最简单线性回归模型开始。
通常我们会使用价格(P)和产量(Q)数据直接做简单线性回归建模：

---

### Trufﬂes example: the simple linear regression

As we all know, the linear regression of two variables is asymmetrical, so there is:

.pull-left[

- the simple **Price** regression is:

`$$\begin{equation} \begin{alignedat}{999} &amp;\widehat{P}=&amp;&amp;+23.23&amp;&amp;+2.14Q\\ &amp;\text{(t)}&amp;&amp;(1.8748)&amp;&amp;(3.2831)\\&amp;\text{(se)}&amp;&amp;(12.3885)&amp;&amp;(0.6518)\\&amp;\text{(fitness)}&amp;&amp; R^2=0.2780;&amp;&amp; \bar{R^2}=0.2522\\&amp; &amp;&amp; F^{\ast}=10.78;&amp;&amp; p=0.0028 \end{alignedat} \end{equation}$$`

]

.pull-right[

- the simple **Quantity** regression  is:

`$$\begin{equation} \begin{alignedat}{999} &amp;\widehat{Q}=&amp;&amp;+10.31&amp;&amp;+0.13P\\ &amp;\text{(t)}&amp;&amp;(3.9866)&amp;&amp;(3.2831)\\&amp;\text{(se)}&amp;&amp;(2.5863)&amp;&amp;(0.0396)\\&amp;\text{(fitness)}&amp;&amp; R^2=0.2780;&amp;&amp; \bar{R^2}=0.2522\\&amp; &amp;&amp; F^{\ast}=10.78;&amp;&amp; p=0.0028 \end{alignedat} \end{equation}$$`

]

???
我们都知道，两个变量的线性回归是不对称的，因此有：

---

### Trufﬂes example: the sample regression line (SRL)

.pull-left[

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="SEM-slide-eng-part1-why_files/figure-html/scatter-truffles-left-1.png" alt="SRL of the Price model"  /&gt;
&lt;p class="caption"&gt;SRL of the Price model&lt;/p&gt;
&lt;/div&gt;

]

.pull-right[

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="SEM-slide-eng-part1-why_files/figure-html/scatter-truffles-right-1.png" alt="SRL of the Quantity model"  /&gt;
&lt;p class="caption"&gt;SRL of the Quantity model&lt;/p&gt;
&lt;/div&gt;

]


???

So, we can not distinguish the supply curve or the demand curve here.


---

### Trufﬂes example: the multi-variables regression model

Of course, we can also use more independent variables X to build the regression models:


`$$\begin{cases}
  \begin{align}
  P &amp; = \hat{\beta}_1+\hat{\beta}_2Q +\hat{\beta}_3DI+\hat{\beta}_2PS +e_1 &amp;&amp; \text{(added P model)}\\
  Q &amp; = \hat{\beta}_1+\hat{\beta}_2P +\hat{\beta}_2PF+e_2  &amp;&amp; \text{(added Q model)}
  \end{align}
\end{cases}$$`




???

Of course, we can also use more independent variables X to build the regression models.

We tried hard to make these supply or demand equations more "reasonable" and "believable".

---

### Trufﬂes example: the multi-variables regression model


- the estimation result of multi-vars **Price** regression model is:

`$$\begin{equation} \begin{alignedat}{999} &amp;\widehat{P}=&amp;&amp;-13.62&amp;&amp;+0.15Q&amp;&amp;+12.36DI&amp;&amp;+1.36PS\\ &amp;\text{(t)}&amp;&amp;(-1.4987)&amp;&amp;(0.3032)&amp;&amp;(6.7701)&amp;&amp;(2.2909)\\&amp;\text{(se)}&amp;&amp;(9.0872)&amp;&amp;(0.4988)&amp;&amp;(1.8254)&amp;&amp;(0.5940)\\&amp;\text{(fitness)}&amp;&amp; R^2=0.8013;&amp;&amp; \bar{R^2}=0.7784\\&amp; &amp;&amp; F^{\ast}=34.95;&amp;&amp; p=0.0000 \end{alignedat} \end{equation}$$`

- the estimation result of multi-vars **Quantity** regression model is:

`$$\begin{equation} \begin{alignedat}{999} &amp;\widehat{Q}=&amp;&amp;+20.03&amp;&amp;+0.34P&amp;&amp;-1.00PF\\ &amp;\text{(t)}&amp;&amp;(16.3938)&amp;&amp;(15.5436)&amp;&amp;(-13.1028)\\&amp;\text{(se)}&amp;&amp;(1.2220)&amp;&amp;(0.0217)&amp;&amp;(0.0764)\\&amp;\text{(fitness)}&amp;&amp; R^2=0.9019;&amp;&amp; \bar{R^2}=0.8946\\&amp; &amp;&amp; F^{\ast}=124.08;&amp;&amp; p=0.0000 \end{alignedat} \end{equation}$$`

???

However, we know that in the demand-supply SEM, reverse causility effect will exist 
between the price  and quantity variables.

So, these simple OLS estimates are unreliable with our intuition.

---
layout: false
class: center, middle, duke-softblue,hide_logo
name: notation

## 18.2 Notations and Definitions

???
In this section, I will give you some important definition and notations about SEM.

---
layout: true
  
&lt;div class="my-header-h2"&gt;&lt;/div&gt;
&lt;div class="watermark1"&gt;&lt;/div&gt;
&lt;div class="watermark2"&gt;&lt;/div&gt;
&lt;div class="watermark3"&gt;&lt;/div&gt;

&lt;div class="my-footer"&gt;&lt;span&gt;huhuaping@   &lt;a href="#chpt18"&gt; Chapter 18. Why Should We Concern SEM ? &lt;/a&gt; | &amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&lt;a href="#notation"&gt;18.2 Notations and Definitions &lt;/a&gt;&lt;/span&gt;&lt;/div&gt; 

---

### Structural SEM (1): algebraic expression A

**Structural equations**: System of equations that directly characterize economic structure or behavior. 

The **algebraic expression** of structural SEM is：

`$$\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
  Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
  Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`


???

algebraic  /ˌældʒɪˈbreɪɪk/

In fact, all examples we have seen in the former section are structural SEM.

___

So we donote the generalized algebraic expression of structural SEM as follows.


---

### Structural SEM (1): Structural coefficients

**Structural coefficients**: Parameters in structural equation that represents an economic outcome or behavioral relationship, including:

`$$\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
  Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
  Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`

&gt;- **.red[En]dogenous structural coefficients**:
`\(\gamma_{11}, \gamma_{21},\cdots, \gamma_{m1}; \cdots; \gamma_{1m}, \gamma_{2m},\cdots, \gamma_{mm}\)`

&gt;- **.red[Ex]ogenous structural coefficients**:
`\(\beta_{11}, \beta_{21},\cdots, \beta_{m1}; \cdots; \beta_{1m}, \beta_{2m},\cdots, \beta_{mm};\)`

???

Firstly, let's define the structural coefficients.

**Structural coefficients** are Parameters in structural SEM that represents an economic outcome or behavioral relationship, including Endogenous structural coefficients (here denoted as ...) and Exogenous structural coefficients (here denoted as ...) .

---

### Structural SEM (1): Structural variables

- **Endogenous variables**: Variables determined by the model.

- **Predetermined variables**：Variables which values are not determined by the model in the **current** time period.

`$$\begin{cases}
  \begin{alignat}{5}
    Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
    Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
    &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
    Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`

.pull-left[
&gt; **Endogenous variables**:  
- Such as:
`\(Y_{t1};Y_{t2}; \cdots; Y_{tm}\)`

]

.pull-right[

&gt; **Predetermined variables**:
- Such as:
`\(X_{..}\)`

]

???

Another important concept is the structural variable, which includes endogenouse variable and predeterminded variable.

Endogenous variables are Variables determined by the model.

Predetermined variables are Variables which values are not determined by the model in the current time period.

We assumed the endogenous variables in this SEM includes all Y_ts, and the predeterminded vairiables include all X_ts.



---

### Structural SEM (1): Predetermined variables

**Predetermined variables**: Variables which values are not determined by the model in the **current** time period, including:

- the **exogenous variables** 

- the **lagged endogenous variables**.

`$$\begin{cases}
  \begin{alignat}{5}
    Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
    Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
    &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
    Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`


???

You should remind that the predetermined variables  consist of both the exogenous variables and thelagged endogenous variables.

---

### Structural SEM (1): Predetermined variables


- **.red[Ex]ogenous variables**: The variables not determined by the model, neither in the **current period** nor in the **lagged period**.

- **Lagged .red[en]dogenous variables**: The lag variable of the endogenous variable in the current period。

.pull-left[

&gt; **current period .red[ex]ogenous**:
- 
`\(X_{t1}, X_{t2},\cdots, X_{tk}\)`.


&gt; **lagged period .red[ex]dogenous**: 
- lagged from
`\(X_{t1}\)`:
`\(X_{t-1,1}; X_{t-2,1};\cdots; X_{t-(T-1),1}\)`
- and lagged from
`\(X_{tk}\)`:
`\(X_{t-1,k}; X_{t-2,k};\cdots; X_{t-(T-1),k}\)`
- 
`\(\cdots\)`

]

.pull-right[
&gt; **lagged .red[en]dogenous**:
- lagged from
`\(Y_{t1}\)`:
`\(Y_{t-1,1}; Y_{t-2,1}; \cdots, Y_{t-(T-1),1}\)`
- and lagged  from
`\(Y_{tm}\)`：
`\(Y_{t-1,m}; Y_{t-2,m}; \cdots;Y_{t-(T-1),m}\)`
- 
`\(\cdots\)`
]

???

&gt; So, you may get two types Exogenous variables, which are current period exogenous, such as all X_ts, and Lagged .red[en]dogenous variables, such as all X_t-s.



---

### Structural SEM (1): Predetermined coefficients

**Predetermined coefficients**: coefficients before predetermined variables. 

`$$\begin{cases}
  \begin{alignat}{5}
    Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
    Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
    &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
    Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`

&gt;Such as:
- all
`\(\beta_{..}\)`

???

Of course, we may denote coefficients before predetermined variables as **Predetermined coefficients**.


---

### Structural SEM (1): algebraic expression B

By simple transformation, the **algebraic expression** of SEM can also show as:


`$$A: \begin{cases}
  \begin{alignat}{5}
    Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
    Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
    &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
    Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`

.small[

`$$\Rightarrow B: \begin{cases}
  \begin{alignat}{5}
  \gamma_{11}Y_{t1} &amp;+ \gamma_{21}Y_{t2}&amp;+\cdots &amp;+\gamma_{m-1,1}Y_{t,m-1} &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{t1}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;=\varepsilon_{t1} \\
  \gamma_{12}Y_{t1} &amp;+\gamma_{22}Y_{t2} &amp;+   \cdots&amp;+\gamma_{m-1,2}Y_{t,m-1} &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;= \varepsilon_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
  \gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}&amp;+ \cdots &amp;+\gamma_{m-1,m}Y_{t,m-1} &amp; +\gamma_{mm}Y_{tm}  &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;=\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`

]


???

By simple transformation, we can also obtain another **algebraic expression** (B) of SEM as show in this slide.

---

### Structural SEM (2): matrix expression

With the Matrix language, the **matrix expression** of SEM was noted as:

`$$\begin{equation}
    \begin{bmatrix}
    Y_1 &amp; Y_2 &amp; \cdots &amp; Y_m \\
  \end{bmatrix} _t
  \begin{bmatrix}
    \gamma_{11} &amp; \gamma_{12} &amp; \cdots &amp; \gamma_{1m} \\
    \gamma_{21} &amp; \gamma_{22} &amp; \cdots &amp; \gamma_{2m} \\
    \cdots &amp; \cdots &amp; \cdots  &amp; \cdots \\
    \gamma_{m1} &amp; \gamma_{m2} &amp; \cdots &amp; \gamma_{mm} \\ 
  \end{bmatrix} + \\
  \begin{bmatrix}
    X_1 &amp; X_2 &amp; \cdots &amp; X_m \\
  \end{bmatrix} _t
  \begin{bmatrix}
    \beta_{11} &amp; \beta_{12} &amp; \cdots &amp; \beta_{1m} \\
    \beta_{21} &amp; \beta_{22} &amp; \cdots &amp; \beta_{2m} \\
    \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\
    \beta_{k1} &amp; \beta_{k2} &amp; \cdots &amp; \beta_{km} \\
  \end{bmatrix} \\ =
  \begin{bmatrix}
    \varepsilon_1 &amp; \varepsilon_2 &amp; \cdots &amp; \varepsilon_m \\
  \end{bmatrix} _t
\end{equation}$$`

???

Here, we arranged the matrix expression of SEM based on former algebraic expression B. 

---

### Structural SEM (2): matrix expression

For Simplicity, we can generized the **matrix expression** of SEM :

`$$\begin{aligned}
&amp; \boldsymbol{y^{\prime}_t} \boldsymbol{\Gamma} &amp;+ &amp; \boldsymbol{x^{\prime}_t} \boldsymbol{B} &amp;= &amp; \boldsymbol{{\varepsilon^{\prime}_t}} \\
&amp;(1 \ast m)(m \ast m) &amp; &amp; (1 \ast k)(k \ast m) &amp; &amp; (1 \ast m)
\end{aligned}$$`


&gt; **where**：
- Bold upper letter and greek means a **matrix**
&gt;
- Bold lower letter and greek means a **column vector**




???

For Simplicity, we can generized the **matrix expression** of SEM as follow.

&gt; we should remind that：
- the dimension of the vector and matrix is important;
- and matrix compatibility  /kəmˌpætəˈbɪləti/ is needed in matrix calculation.

---

### Structural SEM (2): Endogenous coefficients matrix

For the **.red[En]dogenous parameter matrix**
`\(\boldsymbol{\Gamma}\)`：

- To ensure that each equation has a **dependent variable**, then the matrix
`\(\boldsymbol{\Gamma}\)` each column has at least one element of 1
- If matrix
`\(\boldsymbol{\Gamma}\)` is upper triangular matrix, then the SEM is a **recursive** model system.
- For the SEM solution to exist,
`\(\boldsymbol{\Gamma}\)` must be **nonsingular**.


.pull-left[

`$$\begin{equation}
\boldsymbol{\Gamma} =
  \begin{bmatrix}
      \gamma_{11} &amp; \gamma_{12} &amp; \cdots &amp; \gamma_{1m} \\
      \gamma_{21} &amp; \gamma_{22} &amp; \cdots &amp; \gamma_{2m} \\
      \cdots &amp; \cdots &amp; \cdots  &amp; \cdots \\
      \gamma_{m1} &amp; \gamma_{m2} &amp; \cdots &amp; \gamma_{mm} \\ 
  \end{bmatrix} \\
  \text{if }\Rightarrow 
  \begin{bmatrix}
      \gamma_{11} &amp; \gamma_{12} &amp; \cdots &amp; \gamma_{1m} \\
      0 &amp; \gamma_{22} &amp; \cdots &amp; \gamma_{2m} \\
      \cdots &amp; \cdots &amp; \cdots  &amp; \cdots \\
      0 &amp; 0 &amp; \cdots &amp; \gamma_{mm} \\ 
  \end{bmatrix}
\end{equation}$$`

]

.pull-right[

`$$\begin{cases}
  \begin{aligned}
  y_{1t} &amp;=&amp; f_{1}\left(\mathbf{x}_{t}\right)+\varepsilon_{t1} \\ 
  y_{2t} &amp;=&amp; f_{2}\left(y_{t1}, \mathbf{x}_{t}\right)+\varepsilon_{t2} \\ 
  &amp; \vdots &amp; \vdots \\ 
  y_{mt} &amp;=&amp; f_{m}\left(y_{t1}, y_{t2}, \ldots, \mathbf{x}_{t}\right)+\varepsilon_{mt} 
  \end{aligned}
\end{cases}$$`

]

???

Now, let's focus the **.red[En]dogenous parameter matrix** firstly.

---

### Structural SEM (2): Exdogenous coefficients matrix

The **.red[Ex]ogenous coefficients matrix**
`\(\boldsymbol{B}\)`：

`$$\begin{equation}
\boldsymbol{B} =
  \begin{bmatrix}
    \beta_{11} &amp; \beta_{12} &amp; \cdots &amp; \beta_{1m} \\
    \beta_{21} &amp; \beta_{22} &amp; \cdots &amp; \beta_{2m} \\
    \cdots &amp; \cdots &amp; \cdots &amp; \cdots\\
    \beta_{k1} &amp; \beta_{k2} &amp; \cdots &amp; \beta_{km} \\
  \end{bmatrix}
\end{equation}$$`

???

Here is the The **.red[Ex]ogenous coefficients matrix**.

You should pay attention that the first column if SEM contains intercepts.

---

### Reduced SEM (1): algebraic expression

**Reduced equations**:  The equation expresses an **endogenous variable** with all the **predetermined variables** and the **stochastic disturbances**.

`$$\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;=  &amp; +\pi_{11}X_{t1}+\pi_{21}X_{t2} &amp;+\cdots+\pi_{k1}X_{tk} &amp; + v_{t1} \\
  Y_{t2}&amp;=&amp;+\pi_{12}X_{t1}+\pi_{22}X_{t2} &amp;+\cdots+\pi_{k2}X_{tk} &amp; + v_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;  \\
  Y_{tm}&amp;=&amp;+\pi_{1m}X_{t1} +\pi_{2m}X_{t2} &amp;+\cdots+\pi_{km}X_{tk} &amp; + v_{tm}
  \end{alignat}
\end{cases}$$`

???

As you see, we know well with the structural SEMs because we have learned thess models in the economic textbooks.

Now, we will go ahead to  the important concept of reduced SEM.

___

So, a reduced equation is one that expresses an **endogenous variable** solely in terms of the **predetermined variables** and the **stochastic disturbances**.

We denoted the reduced SEM as follows.

---

### Reduced SEM (1):  Reduced coefficients and disturbance

- **Reduced coefficients**: parameters in the reduced SEM.

- **Reduced disturbance**: stochastic disturbance terms in the reduced SEM.

`$$\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;=  &amp; +\pi_{11}X_{t1}+\pi_{21}X_{t2} &amp;+\cdots+\pi_{k1}X_{tk} &amp; + v_{t1} \\
  Y_{t2}&amp;=&amp;+\pi_{12}X_{t1}+\pi_{22}X_{t2} &amp;+\cdots+\pi_{k2}X_{tk} &amp; + v_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;  \\
  Y_{tm}&amp;=&amp;+\pi_{1m}X_{t1} +\pi_{2m}X_{t2} &amp;+\cdots+\pi_{km}X_{tk} &amp; + v_{tm}
  \end{alignat}
\end{cases}$$`


.pull-left[

&gt; Reduced coefficients:
- 
`\(\pi_{11},\pi_{21},\cdots, \pi_{k1}\)`
- 
`\(\pi_{1m},\pi_{2m},\cdots, \pi_{km}\)`. 

]

.pull-right[

&gt; Reduced disturbance:
- 
`\(v_{1},v_2,\cdots, v_m\)`。

]

???

Hence, we induce the concepts of Reduced coefficients and Reduced disturbance.

- Reduced coefficients are parameters in the reduced SEM, such as all `\(\pi_{km}\)`s.

- Reduced disturbance: stochastic disturbance terms in the reduced SEM, such as all `\(v_{m}\)`s.

---

### Reduced SEM (2): matrix expression

`$$\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;=  &amp; +\pi_{11}X_{t1}+\pi_{21}X_{t2} &amp;+\cdots+\pi_{k1}X_{tk} &amp; + v_{t1} \\
  Y_{t2}&amp;=&amp;+\pi_{12}X_{t1}+\pi_{22}X_{t2} &amp;+\cdots+\pi_{k2}X_{tk} &amp; + v_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;  \\
  Y_{tm}&amp;=&amp;+\pi_{1m}X_{t1} +\pi_{2m}X_{t2} &amp;+\cdots+\pi_{km}X_{tk} &amp; + v_{tm}
  \end{alignat}
\end{cases}$$`

For this algebraic reduced SEM, we can note its matrix  form as: 

`$$\begin{equation}
    \begin{bmatrix}
    Y_1 &amp; Y_2 &amp; \cdots &amp; Y_m \\
  \end{bmatrix} _t = \\
  \begin{bmatrix}
    X_1 &amp; X_2 &amp; \cdots &amp; X_m \\
  \end{bmatrix} _t
  \begin{bmatrix}
    \pi_{11} &amp; \pi_{12} &amp; \cdots &amp; \pi_{1m} \\
    \pi_{21} &amp; \pi_{22} &amp; \cdots &amp; \pi_{2m} \\
    \cdots &amp; \cdots &amp; \cdots  &amp; \cdots \\
    \pi_{m1} &amp; \pi_{m2} &amp; \cdots &amp; \pi_{mm} \\ 
  \end{bmatrix}  + 
  \begin{bmatrix}
    v_1 &amp; v_2 &amp; \cdots &amp; v_m \\
  \end{bmatrix} _t
\end{equation}$$`

???

Also, we can denote the matrix form of the reduced SEM as below.

---

### Reduced SEM (2): matrix expression

For simplicity, the matrix expression of reduced SEM can be noted further.

`$$\begin{aligned}
&amp; \boldsymbol{y^{\prime}_t} &amp; =  &amp;\boldsymbol{x^{\prime}_t} \boldsymbol{\Pi}  &amp; + &amp; \boldsymbol{{v^{\prime}_t}}  \\
&amp;(1 \ast m) &amp; &amp; (1 \ast k)(k \ast m) &amp; &amp;  (1 \ast m) 
\end{aligned}$$`


.pull-left[

- the reduced coefficients matrix is :

`$$\begin{equation}
\boldsymbol{\Pi} = 
  \begin{bmatrix}
    \pi_{11} &amp; \pi_{12} &amp; \cdots &amp; \pi_{1m} \\
    \pi_{21} &amp; \pi_{22} &amp; \cdots &amp; \pi_{2m} \\
    \cdots &amp; \cdots &amp; \cdots  &amp; \cdots \\
    \pi_{m1} &amp; \pi_{m2} &amp; \cdots &amp; \pi_{mm} \\ 
  \end{bmatrix}
\end{equation}$$`

]

.pull-right[

- the reduced disturbances vector is:

`$$\begin{equation}
\boldsymbol{{v^{\prime}_t}}=
  \begin{bmatrix}
  v_1 &amp; v_2 &amp; \cdots &amp; v_m \\
  \end{bmatrix}_t
\end{equation}$$`

]

---

### Structural VS Reduced SEM: the two systems

We can induce Reduced Equations from Structural Equations:

`$$\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;= &amp; &amp;+\gamma_{21}Y_{t2}+&amp;\cdots  &amp;+\gamma_{m1}Y_{tm} &amp; +\beta_{11}X_{1t}+\beta_{21}X_{t2} &amp;+\cdots+\beta_{k1}X_{tk} &amp;+\varepsilon_{t1} \\
  Y_{t2}&amp;=&amp;\gamma_{12}Y_{t1} &amp;+  &amp; \cdots &amp;+\gamma_{m2}Y_{tm}&amp;+\beta_{12}X_{t1}+\beta_{22}X_{t2} &amp;+\cdots+\beta_{k2}X_{tk} &amp;+\varepsilon_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;&amp;\vdots  \\
  Y_{tm}&amp;=&amp;\gamma_{1m}Y_{t1}&amp;+\gamma_{2m}Y_{t2}+&amp; \cdots  &amp; &amp;+\beta_{1m}X_{t1} +\beta_{2m}X_{t2} &amp;+\cdots+\beta_{km}X_{tk} &amp;+\varepsilon_{tm} 
  \end{alignat}
\end{cases}$$`


`$$\Rightarrow\begin{cases}
  \begin{alignat}{5}
  Y_{t1}&amp;=  &amp; +\pi_{11}X_{t1}+\pi_{21}X_{t2} &amp;+\cdots+\pi_{k1}X_{tk} &amp; + v_{t1} \\
  Y_{t2}&amp;=&amp;+\pi_{12}X_{t1}+\pi_{22}X_{t2} &amp;+\cdots+\pi_{k2}X_{tk} &amp; + v_{t2}\\
  &amp; \vdots &amp;\vdots &amp;&amp;\vdots &amp;  \\
  Y_{tm}&amp;=&amp;+\pi_{1m}X_{t1} +\pi_{2m}X_{t2} &amp;+\cdots+\pi_{km}X_{tk} &amp; + v_{tm}
  \end{alignat}
\end{cases}$$`

???

Untill now, we have two notation systems. one is the structural SEM, and the other is the reduced SEM.

So, Why we need these two notation systems ?

And what is the relationship between these two notation systems ?

A short answer is that we can deduce the structural parameters with the reduced coefficients.

---

### Structural VS Reduced SEM:  coefficients

The Structural SEM :

`$$\begin{aligned}
 \boldsymbol{y^{\prime}_t} \boldsymbol{\Gamma} +  \boldsymbol{x^{\prime}_t} \boldsymbol{B} =  \boldsymbol{{\varepsilon^{\prime}_t}} 
\end{aligned}$$`

The Reduced SEM:

`$$\begin{aligned}
 \boldsymbol{y^{\prime}_t}  =  \boldsymbol{x^{\prime}_t} \boldsymbol{\Pi}   +  \boldsymbol{{v^{\prime}_t}}  
\end{aligned}$$`

.pull-left[

- where:

`$$\begin{align}
\boldsymbol{\Pi} &amp;= - \boldsymbol{B} \boldsymbol{\Gamma^{-1}}\\
\boldsymbol{{v^{\prime}_t}} &amp;= \boldsymbol{{\varepsilon^{\prime}_t}} \boldsymbol{\Gamma}^{-1} 
\end{align}$$`

]

.pull-right[

- and:

`$$\begin{equation}
\boldsymbol{\Gamma} =
  \begin{bmatrix}
      \gamma_{11} &amp; \gamma_{12} &amp; \cdots &amp; \gamma_{1m} \\
      \gamma_{21} &amp; \gamma_{22} &amp; \cdots &amp; \gamma_{2m} \\
      \cdots &amp; \cdots &amp; \cdots  &amp; \cdots \\
      \gamma_{m1} &amp; \gamma_{m2} &amp; \cdots &amp; \gamma_{mm} \\ 
  \end{bmatrix} 
\end{equation}$$`

]

???

This slide shows the relationship between the structural SEM and the reduced SEM.

And the reduced coefficients equals negetive B times the inverse matrix of structural pars. 

___

`$$\begin{aligned}
 &amp; \boldsymbol{y^{\prime}_t} &amp; =  &amp;-\boldsymbol{x^{\prime}_t} \boldsymbol{B} \boldsymbol{\Gamma^{-1}} &amp; + &amp; \boldsymbol{{\varepsilon^{\prime}_t}} \boldsymbol{\Gamma}^{-1}  \\
&amp;(1 \ast m) &amp; &amp; (1 \ast k)(k \ast m)(m \ast m) &amp; &amp;  (1 \ast m)(m \ast m) 
\end{aligned}$$`


---

### Structural VS Reduced SEM: Moments

Now we concern the first and second moments of the disturbance:

- first , let us assumed the moments of  **structural disturbances** satisfy:

`$$\begin{align}
\mathbf{E[\varepsilon_t | x_t]} &amp;= \mathbf{0} \\
\mathbf{E[\varepsilon_t \varepsilon^{\prime}_t |x_t]} &amp;= \mathbf{\Sigma} \\
E\left[\boldsymbol{\varepsilon}_{t} \boldsymbol{\varepsilon}_{s}^{\prime} | \mathbf{x}_{t}, \mathbf{x}_{s}\right] &amp;=\mathbf{0}, \quad \forall t, s
\end{align}$$`

- then, we can prove that the **reduced disturbances** satify:

`$$\begin{align}
E\left[\mathbf{v}_{t} | \mathbf{x}_{t}\right] &amp;=\left(\mathbf{\Gamma}^{-1}\right)^{\prime} \mathbf{0}=\mathbf{0} \\ E\left[\mathbf{v}_{t} \mathbf{v}_{t}^{\prime} | \mathbf{x}_{t}\right] &amp;=\left(\mathbf{\Gamma}^{-1}\right)^{\prime} \mathbf{\Sigma} \mathbf{\Gamma}^{-1}=\mathbf{\Omega} \\
\text{where: }\mathbf{\Sigma} &amp;=\mathbf{\Gamma}^{\prime} \mathbf{\Omega} \mathbf{\Gamma}
\end{align}$$`

???

This slide shows the first and second moments of the disturbance on both structural and reduced SEM.

First , let us assumed the moments of structural disturbances satisfy following moment conditions. which means that the structural disturbances are drawn from an M-variate distribution with zero conditional expectation and zero covariance. 

Then, we can prove that the reduced disturbances will also be zero conditional expectation and its variance-covariance matrix equals omega.

Finaly, we know the relationship between these two variance-covariance matrix. 

We denote the relationship as Sigma equals transpose Gamma times Omega times Gamma.

---

### Structural VS Reduced SEM: useful expression*

In a sample of data, each joint observation will be one row in a data matrix ( with
`\(T\)` observations):

`$$\begin{align}
\left[\begin{array}{lll}{\mathbf{Y}} &amp; {\mathbf{X}} &amp; {\mathbf{E}}\end{array}\right]=\left[\begin{array}{ccc}{\mathbf{y}_{1}^{\prime}} &amp; {\mathbf{x}_{1}^{\prime}} &amp; {\boldsymbol{\varepsilon}_{1}^{\prime}} \\ {\mathbf{y}_{2}^{\prime}} &amp; {\mathbf{x}_{2}^{\prime}} &amp; {\boldsymbol{\varepsilon}_{2}^{\prime}} \\ {\vdots} &amp; {} \\ {\mathbf{y}_{T}^{\prime}} &amp; {\mathbf{x}_{T}^{\prime}} &amp; {\boldsymbol{\varepsilon}_{T}^{\prime}}\end{array}\right]
\end{align}$$`

then the structural SEM is:

`$$\begin{align}
\mathbf{Y} \mathbf{\Gamma}+\mathbf{X} \mathbf{B}=\mathbf{E}
\end{align}$$`

the first and second moment of structural disturbances is:

`$$\begin{align}
E[\mathbf{E} | \mathbf{X}] &amp;=\mathbf{0} \\ 
E\left[(1 / T) \mathbf{E}^{\prime} \mathbf{E} | \mathbf{X}\right] &amp;=\mathbf{\Sigma}
\end{align}$$`

???

The next two slides will show us some useful relationships under sample data set.

I will not discuss them here, and you should try to learn this content by yourself.

---

### Structural VS Reduced SEM: useful expression*


Assume that:

`$$\begin{align}
(1 / T) \mathbf{X}^{\prime} \mathbf{X} &amp; \rightarrow \mathbf{Q}  \text{ ( a  finite positive definite matrix)} \\
(1 / T) \mathbf{X}^{\prime} \mathbf{E} &amp; \rightarrow \mathbf{0}
\end{align}$$`

then the reduced SEM can be noted as:

`$$\begin{align}
\mathbf{Y} &amp; =\mathbf{X} \boldsymbol{\Pi}+\mathbf{V} &amp;&amp; \leftarrow  \mathbf{V}=\mathbf{E} \mathbf{\Gamma}^{-1}
\end{align}$$`

And we may have following useful results：

`$$\begin{align}
\frac{1}{T}
  \begin{bmatrix}
    {\mathbf{Y}^{\prime}} \\ 
    {\mathbf{X}^{\prime}} \\ 
{\mathbf{V}^{\prime}}
  \end{bmatrix}
  \begin{bmatrix}
    {\mathbf{Y}} &amp; {\mathbf{X}} &amp; {\mathbf{V}}
  \end{bmatrix}
\quad \rightarrow  \quad
  \begin{bmatrix}
    {\mathbf{I}^{\prime} \mathbf{Q} \mathbf{I}+\mathbf{\Omega}} &amp; {\mathbf{I} \mathbf{I}^{\prime} \mathbf{Q}} &amp; {\mathbf{\Omega}} \\
    {\mathbf{Q} \mathbf{I}} &amp; {\mathbf{Q}} &amp; {\mathbf{0}^{\prime}} \\ {\mathbf{\Omega}} &amp; {\mathbf{0}} &amp; {\mathbf{\Omega}}
  \end{bmatrix}
\end{align}$$`
???

The next two slides will show us some useful relationships under sample data set.

I will not discuss them here, and you should try to learn this content by yourself.

---

### Case 1: Keynesian income model (structural SEM)

The Keynesian model of income determination (structural SEM):

`$$\begin{cases}
  \begin{align}
    C_t &amp;= \beta_0+\beta_1Y_t+\varepsilon_t &amp;&amp;\text{(consumption function)}\\
    Y_t &amp;= C_t+I_t &amp;&amp;\text{(income equity)}
  \end{align}
\end{cases}$$`

So the structural SEM contains: 

.pull-left[

2 **endogenous variables**:
- 
`\(c_t;Y_t\)`

]

.pull-right[

1 **predetermined variables**:

- 1 **exogenous variables**:
`\(I_t\)`

- 0 **lagged endogenous variable**.

]

&gt; **Exercise**: can you get the reduced SEM from this structural SEM ? 

???

Now, I will show two cases to illustrate the relationship between the structural SEM and the reduced SEM.

___

Here is the Keynesian model of income determination, and you know this is the structural SEM. 

So, can you deduce the reduced SEM from this structural SEM ?

---

### Case 1: Keynesian income model (reduced SEM)

We can get the reduced SEM from the former structural SEM and denoted (the right):

.pull-left[

`$$\begin{cases}
  \begin{align}
    Y_t &amp;=\frac{\beta_0}{1-\beta_1}+\frac{1}{1-\beta_1}I_t+\frac{\varepsilon_t}{1-\beta_1} \\
    C_t &amp;=\frac{\beta_0}{1-\beta_1}+\frac{\beta_1}{1-\beta_1}I_t+\frac{\varepsilon_t}{1-\beta_1}
  \end{align}
\end{cases}$$`

]

.pull-right[

`$$\begin{cases}
  \begin{align}
    Y_t &amp;= \pi_{11}+\pi_{21}I_t+v_{t1} \\
    C_t &amp;= \pi_{12}+\pi_{22}I_t+v_{t2} 
  \end{align}
\end{cases}$$`
]


where:

`$$\begin{cases}
  \begin{alignat}{5}
    &amp;&amp; \pi_{11}  = \frac{\beta_0}{1-\beta_1}; \quad
    &amp;&amp; \pi_{21}  = \frac{\beta_0}{1-\beta_1}; \quad
    &amp;&amp; v_{t1}  = \frac{\varepsilon_t}{1-\beta_1};\\
    &amp;&amp; \pi_{12}  = \frac{1}{1-\beta_1} ; \quad
    &amp;&amp; \pi_{22}  = \frac{\beta_1}{1-\beta_1} ; \quad
    &amp;&amp; v_{t2}  = \frac{\varepsilon_t}{1-\beta_1}; 
  \end{alignat}
\end{cases}$$`

&gt;there are 2 **structural coefficients**
`\(\beta_0;\beta_1\)` totally ； and 4 **reduced coefficients**
`\(\pi_{11},\pi_{21};\pi_{12},\pi_{22}\)` (There are actually three only !)

???

Surely, We can get the reduced SEM from the former structural SEM with some simple algebraic calculation. 

Also, you can obtain the relationship between the structural parameters and the reduced coefficients.

This is easy because the structural SEM contains only two equations and few structural parameters.

---

### Case 2: Macroeconomic Model (structural SEM)

Consider the **Small Macroeconomic Model** (Structural SEM):

`$$\begin{cases}
  \begin{aligned} 
    \text { consumption: }  c_{t} &amp;=\alpha_{0}+\alpha_{1} y_{t}+\alpha_{2} c_{t-1}+\varepsilon_{t, c} \\ 
    \text { investment: }  i_{t} &amp;=\beta_{0}+\beta_{1} r_{t}+\beta_{2}\left(y_{t}-y_{t-1}\right)+\varepsilon_{t, j} \\ 
    \text { demand: }  y_{t} &amp;=c_{t}+i_{t}+g_{t} 
  \end{aligned}
\end{cases}$$`

where:
`\(c_t =\)` consumption;
`\(y_t =\)` output;
`\(i_t =\)` investment;
`\(r_t =\)` rate;
`\(g_t =\)` government expenditure.

.pull-left[

3 **endogenous variables**:
`\(c_t;i_t;Y_t\)`

4 **predetermined variables**:

- 2 **exogenous variables**: 
`\(r_t;g_t\)`.
- 2 **lagged endogenous variables**:
`\(y_{t-1};c_{t-1}\)`

]

.pull-right[

totally 6 **strutural coefficients**:
`\(\alpha_0,\alpha_1,\alpha_2;\beta_0,\beta_1,\beta_2;\)`

]

???

So, let's go ahead to more complex structural SEM with three equations.


---

### Case 2: Macroeconomic Model（reduced SEM）

We can get the reduced SEM from the former structural SEM: (HOW TO??)

`$$\begin{cases}
  \begin{align}
    c_{t}  = &amp;  [{\alpha_{0}}{\left(1-\beta_{2}\right)}+\beta_{0} \alpha_{1}+\alpha_{1} \beta_{1}  r_{t}+\alpha_{1} g_{t}+\alpha_{2}\left(1-\beta_{2}\right) c_{t-1}-\alpha_{1} \beta_{2} y_{t-1} \\
    +&amp;\left(1-\beta_{2}\right) \varepsilon_{t, c}+\alpha_{1} \varepsilon_{t, j}] /{\Lambda} \\ 
    i_{t}  = &amp; [\alpha_{0} \beta_{2}+\beta_{0}\left(1-\alpha_{1}\right)+\beta_{1}\left(1-\alpha_{1}\right) r_{t}+\beta_{2} g_{t}+\alpha_{2} \beta_{2} c_{t-1}-\beta_{2}\left(1-\alpha_{1}\right) y_{t-1} \\
    +&amp;\beta_{2} \varepsilon_{t, c}+\left(1-\alpha_{1}\right) \varepsilon_{t, j}]/{\Lambda} \\ 
    y_{t} = &amp; [\alpha_{0}+\beta_{0}+\beta_{1} r_{t}+g_{t}+\alpha_{2} c_{t-1}-\beta_{2} y_{t-1}
    +\varepsilon_{t, c}+\varepsilon_{t, j}] /{\Lambda} 
  \end{align}
\end{cases}$$`

where:
`\(\Lambda = 1- \alpha_1 -\beta_2\)`。For simplicity, denote the **reduced SEM** as:

`$$\begin{cases}
  \begin{aligned}
    c_{t} &amp; =  \pi_{11} +\pi_{21}r_t +\pi_{31}g_t +\pi_{41}c_{t-1} +\pi_{51}y_{t-1} +v_{t1} \\
    i_{t} &amp; =  \pi_{12} +\pi_{22}r_t +\pi_{32}g_t +\pi_{42}c_{t-1} +\pi_{52}y_{t-1} +v_{t2} \\
    i_{t} &amp; =  \pi_{13} +\pi_{23}r_t +\pi_{33}g_t +\pi_{43}c_{t-1} +\pi_{53}y_{t-1} +v_{t3}
  \end{aligned}
\end{cases}$$`

&gt; So we have 15 **reduced coefficients** totally!

???

With a little long time calculation, you can obtain the reduced SEM and also the relationship between the structural parameters and the reduced coefficients.

Anyway, the calculation becomes complex and tedious for most of us.

---

### Case 2: Macroeconomic Model (thinking)

**Thinking**：

- What are the purposes of structural SEM and reduced SEM respectively?

- Note the consumption function (in structural SEM): the rate 
`\(i_t\)` does not impact the consumption
`\(c_t\)`!

    - It will be obvious from the reduced SEM that
    `\(\frac{\Delta c_t}{\Delta r_t} = \frac{\alpha_1 \beta_1}{\Lambda}\)`



- Note the consumption function (in structural SEM): What are the reasons for the impact of income 
`\(y_t\)` on consumption
`\(c_t\)`?

    - It's also easy to get the answer by transformation:
    `\(\frac{\Delta c_t}{ \Delta y_t} = \frac{\Delta c_t / \Delta r_t}{\Delta y_t / \Delta r_t} = \frac{\alpha_1 \beta_1 / \Lambda}{ \beta_1 / \Lambda} = \alpha_1\)`

???

So, we shoul rethink that What is the use of structural SEM and reduced SEM respectively?

Can we relieve the works by using alternative approaches?

---

### Case 2: Macroeconomic Model (the relationship)

According to the relationship between Structural SEM and Reduced SEM:

`$$\begin{aligned}
 \boldsymbol{y^{\prime}_t}  =  &amp;-\boldsymbol{x^{\prime}_t} \boldsymbol{\Pi}   +  \boldsymbol{{v^{\prime}_t}}  
 =  -\boldsymbol{x^{\prime}_t} \boldsymbol{B} \boldsymbol{\Gamma^{-1}}  +  \boldsymbol{{\varepsilon^{\prime}_t}} \boldsymbol{\Gamma}^{-1} 
\end{aligned}$$`

Then, the following matrixes can be easily obtained:

.pull-left[

`$$\begin{align}
\mathbf{y}^{\prime} &amp; =
  \begin{bmatrix}
    c &amp; i &amp; y
  \end{bmatrix}\\
\boldsymbol{x}^{\prime} &amp; =
  \begin{bmatrix}
    1 &amp; r &amp; g &amp; c_{-1} &amp; y_{-1}
  \end{bmatrix}
\end{align}$$`

`$$\begin{align}
\mathbf{B}=
  \begin{bmatrix}
    {-\alpha_{0}} &amp; {-\beta_{0}} &amp; {0} \\
    {0} &amp; {-\beta_{1}} &amp; {0} \\ 
    {0} &amp; {0} &amp; {-1} \\ {-\alpha_{2}} &amp; {0} &amp; {0} \\ 
    {0} &amp; {\beta_{2}} &amp; {0}
  \end{bmatrix}
\end{align}$$`

]


.pull-right[

`$$\begin{align}
\Gamma &amp;= 
  \begin{bmatrix}
    {1} &amp; {0} &amp; {-1} \\ 
   {0} &amp; {1} &amp; {-1} \\
    {-\alpha_{1}} &amp; {-\beta_{2}} &amp; {1}
  \end{bmatrix} \\
  \mathbf{\Gamma}^{-1} &amp;=\frac{1}{\Lambda}
  \begin{bmatrix}
    {1-\beta_{2}} &amp; {\beta_{2}} &amp; {1} \\ 
    {\alpha_{1}} &amp; {1-\alpha_{1}} &amp; {1} \\ 
    {\alpha_{1}} &amp; {\beta_{2}} &amp; {1}
  \end{bmatrix}
\end{align}$$`


]

???

Here, we will obtain the reduced coefficients with matrix algebraic calculation.

And you should first know the relationship between Structural SEM and Reduced SEM.

Then, we write down the following vectors and matrixes. Y`, X`,Gamma, B, and inverse Gamma.

Note that the first element of the vector X' is constant one for the intercept in our equations.

I think the difficulty in this calculation is the inverse of matrix Gamma.

---

### Case 2: Macroeconomic Model (calculations)

We can get the same answers: (It's so easy!)

`$$\begin{align}
\boldsymbol{\Pi=-B\Gamma^{-1}}=\frac{1}{\Lambda}
  \begin{bmatrix}
    {\alpha_{0}\left(1-\beta_{2}\right)+\beta_{0} \alpha_{1}} &amp; {\alpha_{0} \beta_{2}+\beta_{0}\left(1-\alpha_{1}\right)} &amp;  {\alpha_{0}+\beta_{0}}   \\ 
    {\alpha_{1} \beta_{1}} &amp; {\beta_{1}\left(1-\alpha_{1}\right)} &amp;  \beta_1  \\ 
      {\alpha_{1}} &amp; {\beta_{2}} &amp; 1 \\
      {\alpha_{2}\left(1-\beta_{2}\right)}&amp; {\alpha_{2} \beta_{2}} &amp; \alpha_2\\
     {-\beta_{2} \alpha_{1}} &amp; {-\beta_{2}\left(1-\alpha_{1}\right)} &amp;-\beta_2
  \end{bmatrix}
\end{align}$$`



`$$\begin{align}
\mathbf{\Pi}^{\prime}=\frac{1}{\Lambda}
  \begin{bmatrix}
  \alpha_{0}\left(1-\beta_{2}\right)+\beta_{0} \alpha_{1} &amp; \alpha_{1} \beta_{1} &amp; \alpha_{1} &amp; \alpha_{2}\left(1-\beta_{2}\right) &amp; -\beta_{2} \alpha_{1} \\
  \alpha_{0} \beta_{2}+\beta_{0}\left(1-\alpha_{1}\right) &amp; \beta_{1}\left(1-\alpha_{1}\right) &amp; \beta_{2} &amp; \alpha_{2} \beta_{2} &amp; -\beta_{2}\left(1-\alpha_{1}\right) \\
  \alpha_{0}+\beta_{0} &amp; \beta_{1} &amp; 1 &amp; \alpha_{2} &amp; -\beta_{2}
  \end{bmatrix}
\end{align}$$`

.pull-left[
- Where:

`$$\Lambda = 1- \alpha_1 -\beta_2$$`

]

.pull-right[
- Remeber that:

`$$\begin{align}
  \mathbf{x}^{\prime}  =
  \begin{bmatrix} 1 &amp; r &amp; g &amp; c_{-1} &amp; y_{-1}
  \end{bmatrix}
\end{align}$$`
]

???

Now, we know that the reduced coefficients matrix equal to negtive B times inverse Gamma.

with the matrix agebraic caculation, we finally get the result here.

And you can compare the transpose Pi with the former result.

___

So, Matrix calculation is a sharp knife, handy and sharp!

You should practice by yourself at least once.

---

### Supplement: inverse matrix solution and procedure*

.notes[
Use the elementary row operation (Gauss-Jordan) to find the inverse matrix:

1. Construct **augmented matrix**

2. Transform the augmented matrix for many times until the goal is achieved.

]

.notes[

Use cofactor, algebraic cofactor and adjoint matrix to get the inverse matrix:

1. Calculate **cofactor matrix** and **algebraic cofactor matrix**;

2. Calculate **adjoint matrix**: it is the **transpose** of the cofactor matrix;

3. Calculate the **determinant** of original matrix : each element of **top row** in the original matrix is multiplied by its corresponding **top row** element in the "cofactor matrix";

4. Calculated the inverse matrix: **1/ determinant** 
`\(\times\)` **adjoint matrix**
]

???

This slide gives you the solution and procedure to obtain the inverse matrix. 


And please try to practice by yourself.

A.用初等行运算（高斯－若尔当）来求逆矩阵：

1. 构造**增广矩阵**

2. 对增广矩阵进行多次变换，直至达到目标。


&lt;br&gt;

B.用余子式、代数余子式和伴随矩阵来求逆矩阵

1. 计算**余子式矩阵**和**代数余子式矩阵**

2. 计算**伴随矩阵**：就是代数余子式矩阵的**转置**

3. 计算原矩阵**行列式**：原矩阵**顶行**的每个元素乘以其对应"代数余子式矩阵"**顶行**元素。

4. 计算得出逆矩阵：**1/行列式** X **伴随矩阵**


---
layout: false
class: center, middle, duke-softblue,hide_logo
name: OLS-apply

## 18.3 Is the OLS Method Still applicable ?

???
In this section, we will discuss the problems with the SEM by using OLS method directly.

---
layout: true
  
&lt;div class="my-header-h2"&gt;&lt;/div&gt;
&lt;div class="watermark1"&gt;&lt;/div&gt;
&lt;div class="watermark2"&gt;&lt;/div&gt;
&lt;div class="watermark3"&gt;&lt;/div&gt;

&lt;div class="my-footer"&gt;&lt;span&gt;huhuaping@   &lt;a href="#chpt18"&gt; Chapter 18. Why Should We Concern SEM ? &lt;/a&gt; | &amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&lt;a href="#OLS-apply"&gt; 18.3 Is OLS Method Still applicable ?&lt;/a&gt;&lt;/span&gt;&lt;/div&gt; 

---

### Endogenous variable problem

Consider Keynes's model of income determination, We will be able to show that 
`\(Y_t\)` and 
`\(u_t\)` will be correlated, thus violating the CLRM **A2** assumption.


`$$\begin{cases}
  \begin{align}
    C_t &amp;= \beta_0+\beta_1Y_t+u_t   &amp;(0&lt;\beta_1&lt;1)  &amp;&amp;\text{( consumption function)}\\
    Y_t &amp;= C_t+I_t  &amp; &amp;&amp;\text{(Income Identity)}
  \end{align}
\end{cases}$$`

By transforming the above structural equation, we obtained:

`$$\begin{align}
Y_t &amp;= \beta_0+\beta_1Y_t+ I_t +u_t   \\
Y_t &amp;= \frac{\beta_0}{1-\beta_1}+\frac{1}{1-\beta_1}I_t+\frac{1}{1-\beta_1}u_t   &amp;&amp; \text{(eq1: Reduced equation)}\\
E(Y_t)&amp;=\frac{\beta_0}{1-\beta_1}+\frac{1}{1-\beta_1}I_t &amp;&amp; \text{(eq2: Take the expectation for both sides)} 
\end{align}$$`

???
Take Keynes's model of income determination. We will be able to show that 
`\(Y_t\)` and 
`\(u_t\)` will be correlated, thus violating the CLRM assumption.

Here, we transform the structural SEM and get the reduced equation for the endogenous variable Y_t.

---

### Endogenous variable problem

Further more:

`$$\begin{align}
Y_t - E(Y_t)&amp; = \frac{u_t}{1-\beta_1} &amp;&amp; \text{(eq 1 - eq 2)}\\
u_t-E(u_t) &amp;= u_t &amp;&amp; \text{(eq 3: Expectation is equal to 0)} \\
cov(Y_t,u_t) &amp;= E([Y_t-E(Y_t)][u_t-E(u_t)])  &amp;&amp; \text{(eq 4: Covariance definition)}\\ 
&amp;=\frac{E(u^2_t)}{1-\beta_1} &amp;&amp; \text{(eq 5: Variance definition)}\\
&amp;=\frac{\sigma^2}{1-\beta_1}\neq 0 &amp;&amp; \text{(eq 6: The variance is not 0)}
\end{align}$$`

- Therefore, the consumption equation of the Keynesian model will not satisfy the CLRM A2 assumption. 

- Thus, OLS method cannot be used to obtain **Best linear unbiased estimator** (BLUE) for consumption equation.



???

Here, I give you the hints to obtain the covariance of Y_t and u_t.

And we can prove that the demand equation of the Keynesian model will not satisfy the assumption that 
`\(Y_t\)` is not related to
`\(u_t\)` in the CLRM hypothesis. 

Thus, OLS method cannot be used to obtain **Best linear unbiased estimator** (BLUE) for demand equation.


---

### The OLS estimator of the coefficient is biased

Furthermore, the OLS estimator is biased to its true 
`\(\beta_1\)`, which means
`\(E(\hat{\beta}_1) \neq \beta_1\)`. The proof show as below.

`$$\begin{cases}
  \begin{align}
    C_t &amp;= \beta_0+\beta_1Y_t+u_t   &amp;(0&lt;\beta_1&lt;1)  &amp;&amp;\text{( consumption function)}\\
    Y_t &amp;= C_t+I_t  &amp; &amp;&amp;\text{(Income Identity)}
  \end{align}
\end{cases}$$`

`$$\begin{align}
\hat{\beta}_1 
= \frac{\sum{c_ty_t}}{\sum{y^2_t}}
= \frac{\sum{C_ty_t}}{\sum{y^2_t}}
= \frac{\sum{\left [ (\beta_0+\beta_1Y_t+u_t)y_t \right ]}}{\sum{y^2_t}} 
 = \beta_1 + \frac{\sum{u_ty_t}}{\sum{y^2_t}} 
&amp;&amp; \text{(eq 1)}
\end{align}$$`

Take the expectation of both sides in eq 1, so:

`$$\begin{align}
E(\hat{\beta}_1) &amp;= \beta_1 + E \left ( \frac{\sum{u_ty_t}}{\sum{y^2_t}} \right )
\end{align}$$`

&gt; Question: is the expactation
`\(E\left (\frac {\sum {u_ty_t}} {\sum {y^2_t}} \right)\)`  equal to zero?

???

It will be further demonstrated that the OLS method is biased to estimate 
`\(\beta_1\)`, whicn means
`\(E(\hat{\beta}_1) \neq \beta_1\)`.

___

- The following question is that if the expactation
`\(E\left (\frac {\sum {u_ty_t}} {\sum {y^2_t}} \right)\)` is equal to zero?

- We can prove that it will not be equal to 0 with the following two slides from proof appendix 1 to appendix 2.

I will not try to discuss the details for these provement here, so you should do this after our lessons.

---

### Supplement: Proof 1/2

`$$\begin{align}
 \frac{\sum{c_ty_t}}{\sum{y^2_t}}
&amp;= \frac{\sum{(C_t-\bar{C})(Y_t - \bar{Y})}}{\sum{y^2_t}}
= \frac{\sum{(C_t-\bar{C})y_t}}{\sum{y^2_t}} \\
&amp; =\frac{\sum{C_ty_t}-\sum{\bar{C}y_t}}{\sum{y^2_t}}
 =\frac{\sum{C_ty_t}-\sum{\bar{C}(Y_t- \bar{Y})}}{\sum{y^2_t}} \\
&amp; = \frac{\sum{C_ty_t}-\bar{C}\sum{Y_t}- \sum{\bar{C}\bar{Y}}}{\sum{y^2_t}} 
= \frac{\sum{C_ty_t}-\bar{C}\sum{Y_t}- n{\bar{C}\bar{Y}}}{\sum{y^2_t}}
= \frac{\sum{C_ty_t}}{\sum{y^2_t}}
\end{align}$$`

`$$\begin{align}
\hat{\beta_1} &amp; = \frac{\sum\left(\beta_{0}+\beta_{1} Y_{t}+u_{t}\right) y_{t}}{\sum y_{t}^{2}} 
= \frac{\sum{\beta_{0}y_t} +\sum{\beta_1Y_ty_t}+\sum{u_{t}y_t} }{\sum y_{t}^{2}} \\
&amp; = \frac{\beta_1\sum{(y_t+\bar{Y})y_t}+\sum{u_{t}y_t} }{\sum y_{t}^{2}}
=\beta_{1}+\frac{\sum y_{t} u_{t}}{\sum y_{t}^{2}}
\end{align}$$`

`$$\begin{align}
 \Leftarrow &amp;\sum{y_t} =0  ; &amp;&amp;  \frac{\sum{Y_ty_t}}{y^2_t} = 1
\end{align}$$`

---

### Supplement: Proof 2/2

Conduct the limit to probability:

`$$\begin{align}
\operatorname{plim}\left(\hat{\beta}_{1}\right) &amp;=\operatorname{plim}\left(\beta_{1}\right)+\operatorname{plim}\left(\frac{\sum y_{t} u_{t}}{\sum y_{t}^{2}}\right) \\
&amp;=\operatorname{plim}\left(\beta_{1}\right)+\operatorname{plim}\left(\frac{\sum y_{t} u_{t} / n}{\sum y_{t}^{2} / n}\right) =\beta_{1}+\frac{\operatorname{plim}\left(\sum y_{t} u_{t} / n\right)}{\operatorname{plim}\left(\sum y_{t}^{2} / n\right)} 
\end{align}$$`

And we've shown that:

`$$\begin{align}
cov(Y_t,u_t) &amp;= E([Y_t-E(Y_t)][u_t-E(u_t)])  =\frac{E(u^2_t)}{1-\beta_1} 
=\frac{\sigma^2}{1-\beta_1}\neq 0 
\end{align}$$`

Therefore we finaly prove:
`\(E \left ( \frac{\sum{u_ty_t}}{\sum{y^2_t}} \right ) \neq 0\)`

---

### Simulation: artificially population

Here, we construct an artificially controlled population for our Keynes's SEM model.

`$$\begin{cases}
  \begin{align}
  C_t &amp;= \beta_0+\beta_1Y_t+u_t   &amp;(0&lt;\beta_1&lt;1)  &amp;&amp;\text{(consumption function)}\\
  Y_t &amp;= C_t+I_t  &amp; &amp;&amp;\text{(Income Identity)}
  \end{align}
\end{cases}$$`

`$$\begin{cases}
  \begin{align}
  C_t &amp;= 2+ 0.8Y_t+u_t   &amp;(0&lt;\beta_1&lt;1)  &amp;&amp;\text{(consumption function)}\\
  Y_t &amp;= C_t+I_t  &amp; &amp;&amp;\text{(Income Identity)}
  \end{align}
\end{cases}$$`

The artificially controlled population is set to:

- `\(\beta_0=2, \beta_1=0.8, I_t \leftarrow \text{given values}\)`
- `\(E(u_t)=0, var(u_t)=\sigma^2=0.04\)`
- `\(E(u_tu_{t+j})=0,j \neq 0\)`
- `\(cov(u_t,I_t)=0\)`

???

I will give you a numerical simulation to illustrate the problems with SEM by using OLS method directly.

Here, we construct an artificially (/ˌɑːtɪˈfɪʃəli/) controlled population for our Keynes's SEM model.

As you see, we control the population by setting following parameters and relationships.



---

### Simulation: the data sets

The simulation data under given conditions are:

<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-f5d68301c27f75860eef" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-f5d68301c27f75860eef">{"x":{"filter":"none","vertical":false,"caption":"<caption><\/caption>","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20"],[18.15697,19.5998,21.93468,21.55145,21.88427,22.42648,25.4094,22.69523,24.36465,24.39334,24.09215,24.8745,25.3158,26.30465,25.78235,26.08018,27.2444,28.00963,30.89301,28.98706],[16.15697,17.5998,19.73468,19.35145,19.48427,20.02648,22.8094,20.09523,21.56465,21.59334,21.09215,21.8745,22.1158,23.10465,22.38235,22.68018,23.6444,24.40963,27.09301,25.18706],[2,2,2.2,2.2,2.4,2.4,2.6,2.6,2.8,2.8,3,3,3.2,3.2,3.4,3.4,3.6,3.6,3.8,3.8],[-0.368606,-0.0800400000000003,0.186935999999999,0.110289999999999,-0.0231460000000041,0.085295999999996,0.481879999999997,-0.0609539999999988,0.0729299999999995,0.0786680000000004,-0.181570000000001,-0.0251000000000019,-0.136839999999999,0.060929999999999,-0.243530000000003,-0.183964,-0.151119999999999,0.00192599999999743,0.378601999999997,-0.00258800000000292]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Y<\/th>\n      <th>C<\/th>\n      <th>I<\/th>\n      <th>u<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"tip","columnDefs":[{"targets":1,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 4, 3, \",\", \".\", null);\n  }"},{"targets":2,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 4, 3, \",\", \".\", null);\n  }"},{"targets":4,"render":"function(data, type, row, meta) {\n    return type !== 'display' ? data : DTWidget.formatRound(data, 4, 3, \",\", \".\", null);\n  }"},{"className":"dt-center","targets":"_all"},{"visible":false,"targets":0},{"orderable":false,"targets":0}],"pageLength":8,"digits":4,"order":[],"autoWidth":false,"orderClasses":false,"lengthMenu":[8,10,25,50,100]}},"evals":["options.columnDefs.0.render","options.columnDefs.1.render","options.columnDefs.2.render"],"jsHooks":[]}</script>

---

### Simulation: manual calculation

According to the above formula, the regression coefficient can be calculated as follows:

Easy to calculate:
`\(\sum{u_ty_t}\)`
=3.8000

And: 
`\(\sum{y^2_t}\)`
=184.0000

And: 
`\(\frac{\sum{u_ty_t}}{\sum{y^2_t}}\)`
=0.0207

Hence：
`\(\hat{\beta}_1 = \beta_1 + \frac{\sum{u_ty_t}}{\sum{y^2_t}}\)`
=0.8+0.0207= 0.8207

This also means that
`\(\hat{\beta_1}\)` 
is different from
`\(\beta_1=0.8\)`, and the differnce is 0.0207.

???

According to the former provment procedure, we can manually calculate the OLS coefficient of beta_1.

Finally, the OLS estimator of beta_1 equals 0.8207, and not equal to its true value 0.8 we have set before.

So, the OLS estimator is biased with our simulation data set.

---

### Simulation: scatter plots

&lt;img src="SEM-slide-eng-part1-why_files/figure-html/scatter-YC-1.png" style="display: block; margin: auto;" /&gt;

???

Here, we draw the scatter of Y and C.


---

### Simulation: regression report 1

Next, we used the simulated data for R analysis to obtain the original OLS report.


```

Call:
lm(formula = mod_monte$mod.C, data = monte)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.2700 -0.1586 -0.0013  0.0927  0.4631 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   1.4940     0.3541    4.22  0.00052 ***
Y             0.8207     0.0143   57.21  &lt; 2e-16 ***
---
Signif. codes:  
0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.2 on 18 degrees of freedom
Multiple R-squared:  0.995,	Adjusted R-squared:  0.994 
F-statistic: 3.27e+03 on 1 and 18 DF,  p-value: &lt;2e-16
```

---

### Simulation: regression report 2

The tidy report of OLS estimation shows below.

`$$\begin{alignedat}{999}
&amp;\widehat{C}=&amp;&amp;+1.49&amp;&amp;+0.82Y\\
&amp;\text{(t)}&amp;&amp;(4.2188)&amp;&amp;(57.2090)\\
&amp;\text{(se)}&amp;&amp;(0.3541)&amp;&amp;(0.0143)\\
&amp;\text{(fitness)}&amp;&amp; n=20;&amp;&amp; R^2=0.9945;&amp;&amp; \bar{R^2}=0.9942\\
&amp; &amp;&amp; F^{\ast}=3272.87;&amp;&amp; p=0.0000\\
\end{alignedat}$$`

???

for sum, The results of direct use of OLS regression also show bias.


---

### Simulation: sample regression line (SRL)



&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="SEM-slide-eng-part1-why_files/figure-html/scatter-YC-fit-1.png" alt="The SRL"  /&gt;
&lt;p class="caption"&gt;The SRL&lt;/p&gt;
&lt;/div&gt;

???

And the OLS slope is 0.8207.

---

### Conclusions and points

So let's summarize this chapter.

- Compared with the single-equation model, the SEM involves more than one dependent or endogenous variable. So there must be as many equations as  endogenous variables.

- SEM always show that the endogenous variables are correlated with stochastic terms in other equations.


- Classical OLS may not be appropriate because the estimators are inconsistent.


???

In the next chapter, we will learn the identification of SEM.

See you in my next class. Goodbye.

---
exclude: true

### reference

- [SimultaneousEq.pdf](https://web.sgh.waw.pl/~mrubas/AdvEcon/pdf/T3_SimultaneousEq.pdf)

---
layout:false
background-image: url("../pic/thank-you-gif-funny-little-yellow.gif")
class: inverse,center

# End Of This Chapter
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
