---
title: 自动化数据抓取技术(V)：APACHA的视觉识别
author: huhuaping
date: '2020-12-05'
slug: web-scraping-tech-vision-volidation
categories:
  - R
tags:
  - webscrape
subtitle: ''
summary: ''
authors: []
lastmod: '2020-12-05T16:30:46+08:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
output:
  blogdown::html_page:
    toc: true
---

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>

<div id="TOC">
<ul>
<li><a href="#常见问题场景及处理方法">常见问题场景及处理方法</a><ul>
<li><a href="#中文乱码">中文乱码</a></li>
<li><a href="#nodes节点选择">nodes节点选择</a></li>
<li><a href="#利用chrome浏览器查看json数据">利用chrome浏览器查看json数据</a></li>
</ul></li>
</ul>
</div>

<div id="常见问题场景及处理方法" class="section level2">
<h2>常见问题场景及处理方法</h2>
<div id="中文乱码" class="section level3">
<h3>中文乱码</h3>
<p>中文乱码问题再次出现，见各种乱码问题。编码问题详解可以参看<a href="https://kunststube.net/encoding/">What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text</a>。</p>
<p>1.快捷办法，直接抓取网页表格，无论如何都显示乱码。只能放弃。</p>
<pre class="r"><code># look for table element
tableElem &lt;- remDr$findElement(using = &quot;id&quot;, &quot;courseTable&quot;)

txt &lt;- tableElem$getElementAttribute(&quot;outerHTML&quot;)[[1]]

table &lt;- XML::readHTMLTable(txt, header=F, as.data.frame=TRUE)[[1]]</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>暴力抓取网页元素总，虽然颇为费劲，但总是可行。</li>
</ol>
<pre class="r"><code># scrape the date and room 
v_date &lt;- txt %&gt;% read_html() %&gt;%  xml_nodes(&quot;tbody&quot;) %&gt;% xml_nodes(&quot;td:nth-child(2)&quot;) %&gt;% xml_text()

v_room &lt;- txt %&gt;% read_html() %&gt;%  xml_nodes(&quot;tbody&quot;) %&gt;% xml_nodes(&quot;td:nth-child(4)&quot;) %&gt;% xml_text()

# tidy data.frame
info &lt;- data.frame(date=v_date, room =v_room) %&gt;%
  separate(col = &quot;date&quot; , into = c(&quot;date&quot;,&quot;week&quot;, &quot;weekday&quot;, &quot;slot&quot;), sep = &quot; &quot;)</code></pre>
</div>
<div id="nodes节点选择" class="section level3">
<h3>nodes节点选择</h3>
<p>如何选择和提取网页多个节点tr下第n个元素td下的文本text。参看<a href="https://stackoverflow.com/questions/56782998/how-to-extract-text-in-second-p-element-inside-div">网络解答</a></p>
<pre class="r"><code>    txt %&gt;% 
  read_html() %&gt;%  
  xml_nodes(&quot;tbody&quot;) %&gt;% 
  xml_nodes(&quot;td:nth-child(2)&quot;) %&gt;% 
  xml_text()</code></pre>
</div>
<div id="利用chrome浏览器查看json数据" class="section level3">
<h3>利用chrome浏览器查看json数据</h3>
<p>具体参看<a href="https://stackoverflow.com/questions/31775176/scraping-javascript-in-r-with-rselenium">资料</a></p>
<pre><code>Using Chrome: Right-click &gt; Inspect; navigate to Network tab &gt; type in .json &gt; Search &gt; Refresh Site (to catch calls made prior) </code></pre>
</div>
</div>
